## Basic Paper List
- AlexNet
- ResNet
- Transformer
- *YOLO
## Reflex-based and Stated-based
## Share:PARROT
## Share:Knowledge Distillation
知识蒸馏的最简单形式是在具有软目标分布的传递集上训练蒸馏模型。到目前为止,我们应该知道有两个目标用于训练学生模型。一个是正确的标签(硬目标),另一个是从教师网络生成的软标签(软目标)。因此,目标函数是两个不同目标函数的加权平均值。 第一个目标函数是学生预测和软目标之间的交叉熵损失,第二个目标函数是学生输出和正确标签之间的交叉熵损失。最好的结果通常是通过在第二目标函数上使用较低的权重来获得的。
## Code Homework
- GAN
- Clip
- VIT
- Diffusion model
- MAE
## Paper reading Homework
- Agent
- Search
- Markov Decision Processes
- Bayesian Network
- Reinforcement Learning